{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfeCxDdJnnEz",
        "outputId": "8d00c1dc-1fde-4c9e-e92a-739235a2c5d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neo4j in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from neo4j) (2025.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "gzip: wiki-Vote.txt already exists; do you wish to overwrite (y or n)? n\n",
            "\tnot overwritten\n"
          ]
        }
      ],
      "source": [
        "# Install Neo4j driver\n",
        "!pip install neo4j pandas\n",
        "\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "from neo4j import GraphDatabase\n",
        "import time\n",
        "\n",
        "# Download dataset\n",
        "url = \"https://snap.stanford.edu/data/wiki-Vote.txt.gz\"\n",
        "urllib.request.urlretrieve(url, \"wiki-Vote.txt.gz\")\n",
        "!gunzip wiki-Vote.txt.gz\n",
        "\n",
        "# Neo4j Aura credentials\n",
        "URI = \"neo4j+s://155cc552.databases.neo4j.io\"\n",
        "AUTH = (\"neo4j\", \"MYPASS\") #USED MY PASS HERE\n",
        "\n",
        "driver = GraphDatabase.driver(URI, auth=AUTH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare CSV files\n",
        "edges = []\n",
        "nodes = set()\n",
        "\n",
        "with open('wiki-Vote.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        if line.startswith('#'):\n",
        "            continue\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) == 2:\n",
        "            src, dst = int(parts[0]), int(parts[1])\n",
        "            edges.append({'src': src, 'dst': dst})\n",
        "            nodes.add(src)\n",
        "            nodes.add(dst)\n",
        "\n",
        "# Create DataFrames\n",
        "nodes_df = pd.DataFrame({'id': sorted(list(nodes))})\n",
        "edges_df = pd.DataFrame(edges)\n",
        "\n",
        "print(f\"Nodes: {len(nodes_df)}\")\n",
        "print(f\"Edges: {len(edges_df)}\")\n",
        "\n",
        "nodes_df.to_csv('nodes.csv', index=False)\n",
        "edges_df.to_csv('edges.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07c0LIxvpNsl",
        "outputId": "004f2932-b906-4e1d-c1ff-2c28e60f7da1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes: 7115\n",
            "Edges: 103689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Load data in neo4j\n",
        "'''\n",
        "// Clear existing data\n",
        "MATCH (n) DETACH DELETE n;\n",
        "\n",
        "// Create unique constraint\n",
        "CREATE CONSTRAINT user_id IF NOT EXISTS\n",
        "FOR (u:User) REQUIRE u.id IS UNIQUE;\n",
        "\n",
        "// Load nodes from Google Drive CSV\n",
        "LOAD CSV WITH HEADERS FROM 'https://drive.google.com/uc?id=18kfz6J9MiTSLDF5s9wGG-RZ52uGFr7Vc&export=download' AS row\n",
        "CREATE (:User {id: toInteger(row.id)});\n",
        "\n",
        "// Load edges from Google Drive CSV\n",
        "LOAD CSV WITH HEADERS FROM 'https://drive.google.com/uc?id=1mTbuUcUh2-3BNirwZWb6OpFEe1d5htBP&export=download' AS row\n",
        "MATCH (src:User {id: toInteger(row.src)}), (dst:User {id: toInteger(row.dst)})\n",
        "CREATE (src)-[:VOTED_FOR]->(dst);\n",
        "'''\n",
        "\n",
        "#USING THAT\n",
        "\n",
        "def load_data(driver):\n",
        "    with driver.session() as session:\n",
        "\n",
        "        # Clear existing data\n",
        "        print(\"Clearing old data...\")\n",
        "        session.run(\"MATCH (n) DETACH DELETE n\")\n",
        "\n",
        "        # Create unique constraint (safe)\n",
        "        print(\"Creating unique constraint...\")\n",
        "        session.run(\"\"\"\n",
        "            CREATE CONSTRAINT user_id IF NOT EXISTS\n",
        "            FOR (u:User) REQUIRE u.id IS UNIQUE\n",
        "        \"\"\")\n",
        "\n",
        "        # Load nodes using new transaction batching\n",
        "        print(\"Loading nodes.csv...\")\n",
        "        session.run(\"\"\"\n",
        "            LOAD CSV WITH HEADERS FROM\n",
        "            'https://drive.google.com/uc?id=18kfz6J9MiTSLDF5s9wGG-RZ52uGFr7Vc&export=download'\n",
        "            AS row\n",
        "            CALL (row) {\n",
        "                CREATE (:User {id: toInteger(row.id)})\n",
        "            } IN TRANSACTIONS OF 1000 ROWS\n",
        "        \"\"\")\n",
        "\n",
        "        # Load edges using new transaction batching\n",
        "        print(\"Loading edges.csv...\")\n",
        "        session.run(\"\"\"\n",
        "            LOAD CSV WITH HEADERS FROM\n",
        "            'https://drive.google.com/uc?id=1mTbuUcUh2-3BNirwZWb6OpFEe1d5htBP&export=download'\n",
        "            AS row\n",
        "            CALL {\n",
        "                WITH row\n",
        "                MATCH (src:User {id: toInteger(row.src)}),\n",
        "                      (dst:User {id: toInteger(row.dst)})\n",
        "                CREATE (src)-[:VOTED_FOR]->(dst)\n",
        "            } IN TRANSACTIONS OF 1000 ROWS\n",
        "        \"\"\")\n",
        "\n",
        "        print(\"Data successfully loaded\")\n",
        "\n",
        "        print(\"Verifying data counts...\")\n",
        "        result = session.run(\"\"\"\n",
        "            MATCH (u:User)\n",
        "            WITH count(u) AS userCount\n",
        "            MATCH ()-[r:VOTED_FOR]->()\n",
        "            RETURN userCount, count(r) AS relCount\n",
        "        \"\"\")\n",
        "\n",
        "        record = result.single()\n",
        "        user_count = record[\"userCount\"]\n",
        "        rel_count = record[\"relCount\"]\n",
        "        print(f\"Import summary → Users: {user_count}, Relationships: {rel_count}\")\n",
        "\n",
        "load_data(driver)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY5WiRL9plUb",
        "outputId": "3ceda4a2-812e-4f02-9657-3edca648767b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clearing old data...\n",
            "Creating unique constraint...\n",
            "Loading nodes.csv...\n",
            "Loading edges.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: <GqlStatusObject gql_status='01N00', status_description='warn: feature deprecated. CALL subquery without a variable scope clause is deprecated. Use CALL (row) { ... }', position=<SummaryInputPosition line=5, column=13, offset=166>, raw_classification='DEPRECATION', classification=<NotificationClassification.DEPRECATION: 'DEPRECATION'>, raw_severity='WARNING', severity=<NotificationSeverity.WARNING: 'WARNING'>, diagnostic_record={'_classification': 'DEPRECATION', '_severity': 'WARNING', '_position': {'offset': 166, 'line': 5, 'column': 13}, 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: \"\\n            LOAD CSV WITH HEADERS FROM\\n            'https://drive.google.com/uc?id=1mTbuUcUh2-3BNirwZWb6OpFEe1d5htBP&export=download'\\n            AS row\\n            CALL {\\n                WITH row\\n                MATCH (src:User {id: toInteger(row.src)}),\\n                      (dst:User {id: toInteger(row.dst)})\\n                CREATE (src)-[:VOTED_FOR]->(dst)\\n            } IN TRANSACTIONS OF 1000 ROWS\\n        \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully loaded\n",
            "Verifying data counts...\n",
            "Import summary → Users: 7115, Relationships: 103689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from neo4j.exceptions import ServiceUnavailable, SessionExpired\n",
        "\n",
        "def run_metrics(driver, sample_size=500):\n",
        "    results = {}\n",
        "\n",
        "    try:\n",
        "        with driver.session() as session:\n",
        "            # 1. Count nodes and edges\n",
        "            print(\"1. Counting nodes and edges...\")\n",
        "            start = time.time()\n",
        "            try:\n",
        "                nodes_result = session.run(\"MATCH (n:User) RETURN count(n) AS cnt\")\n",
        "                edges_result = session.run(\"MATCH ()-[r:VOTED_FOR]->() RETURN count(r) AS cnt\")\n",
        "                nodes = nodes_result.single()['cnt']\n",
        "                edges = edges_result.single()['cnt']\n",
        "                results['basic_count'] = time.time() - start\n",
        "                print(f\"   Nodes: {nodes}, Edges: {edges}\")\n",
        "                print(f\"   Time: {results['basic_count']:.3f}s\")\n",
        "            except Exception as e:\n",
        "                print(f\"   Error: {e}\")\n",
        "                return None\n",
        "\n",
        "            if nodes == 0:\n",
        "                print(\"   No nodes found\")\n",
        "                return results\n",
        "\n",
        "            actual_sample_size = min(sample_size, nodes)\n",
        "\n",
        "            # 2. Get sample nodes\n",
        "            print(f\"2. Sampling {actual_sample_size} nodes...\")\n",
        "            try:\n",
        "                node_ids = [r['nodeId'] for r in session.run(\n",
        "                    \"MATCH (n:User) RETURN n.id AS nodeId LIMIT $limit\",\n",
        "                    limit=actual_sample_size\n",
        "                )]\n",
        "                print(f\"   Sampled {len(node_ids)} nodes\")\n",
        "            except Exception as e:\n",
        "                print(f\"   Error: {e}\")\n",
        "                node_ids = []\n",
        "\n",
        "            if not node_ids:\n",
        "                return results\n",
        "\n",
        "            # 3. Weakly Connected Components\n",
        "            print(\"3. Computing WCC (approx)...\")\n",
        "            start = time.time()\n",
        "            max_component_size = 0\n",
        "            processed = 0\n",
        "\n",
        "            for nid in node_ids[:50]:\n",
        "                try:\n",
        "                    comp_size = session.run(\"\"\"\n",
        "                        MATCH (n:User {id: $nid})\n",
        "                        CALL apoc.path.subgraphNodes(n, {relationshipFilter:'VOTED_FOR|<VOTED_FOR', maxNodes: 1000})\n",
        "                        YIELD node\n",
        "                        RETURN count(node) AS size\n",
        "                    \"\"\", nid=nid).single()['size']\n",
        "                    if comp_size > max_component_size:\n",
        "                        max_component_size = comp_size\n",
        "                    processed += 1\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "\n",
        "            results['wcc'] = time.time() - start\n",
        "            print(f\"   Largest WCC: {max_component_size} nodes\")\n",
        "            print(f\"   Time: {results['wcc']:.3f}s\")\n",
        "\n",
        "            # 4. Strongly Connected Components\n",
        "            print(\"4. Computing SCC (approx)...\")\n",
        "            start = time.time()\n",
        "            max_scc_size = 0\n",
        "            scc_sample = random.sample(node_ids, min(20, len(node_ids)))\n",
        "            processed = 0\n",
        "\n",
        "            for nid in scc_sample:\n",
        "                try:\n",
        "                    scc_result = session.run(\"\"\"\n",
        "                        MATCH (n:User {id: $nid})\n",
        "                        CALL apoc.path.subgraphAll(n, {\n",
        "                            relationshipFilter: 'VOTED_FOR',\n",
        "                            maxNodes: 500\n",
        "                        }) YIELD nodes\n",
        "                        RETURN size(nodes) AS size\n",
        "                    \"\"\", nid=nid)\n",
        "                    scc_size = scc_result.single()['size']\n",
        "                    if scc_size > max_scc_size:\n",
        "                        max_scc_size = scc_size\n",
        "                    processed += 1\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "\n",
        "            results['scc'] = time.time() - start\n",
        "            print(f\"   Largest SCC: {max_scc_size} nodes\")\n",
        "            print(f\"   Time: {results['scc']:.3f}s\")\n",
        "\n",
        "            # 5. Triangle count\n",
        "            print(\"5. Computing triangle counts...\")\n",
        "            start = time.time()\n",
        "            try:\n",
        "                triangle_result = session.run(\"\"\"\n",
        "                    MATCH (a:User)-[:VOTED_FOR]->(b:User)-[:VOTED_FOR]->(c:User)-[:VOTED_FOR]->(a:User)\n",
        "                    RETURN count(*) AS tri_count\n",
        "                \"\"\")\n",
        "                triangle_count = triangle_result.single()['tri_count']\n",
        "                results['triangles'] = time.time() - start\n",
        "                print(f\"   Triangles: {triangle_count}\")\n",
        "                print(f\"   Time: {results['triangles']:.3f}s\")\n",
        "            except Exception as e:\n",
        "                print(f\"   Error: {e}\")\n",
        "                results['triangles'] = time.time() - start\n",
        "\n",
        "            # 6. Clustering coefficient - fixed\n",
        "            print(\"6. Computing Clustering Coefficient...\")\n",
        "            start = time.time()\n",
        "            try:\n",
        "                cc_result = session.run(\"\"\"\n",
        "                    MATCH (n:User)\n",
        "                    WITH n LIMIT 50\n",
        "                    MATCH (n)-[:VOTED_FOR]-(m)\n",
        "                    WITH n, collect(m) AS neighbors\n",
        "                    WHERE size(neighbors) >= 2\n",
        "                    UNWIND range(0, size(neighbors)-2) AS i\n",
        "                    UNWIND range(i+1, size(neighbors)-1) AS j\n",
        "                    WITH n, neighbors, neighbors[i] AS n1, neighbors[j] AS n2\n",
        "                    WHERE (n1)-[:VOTED_FOR]-(n2)\n",
        "                    WITH n, count(*) AS connected_pairs, size(neighbors) AS k\n",
        "                    RETURN avg(2.0 * connected_pairs / (k * (k-1))) AS avg_cc\n",
        "                \"\"\")\n",
        "                avg_cc = cc_result.single()['avg_cc'] or 0\n",
        "                results['clustering'] = time.time() - start\n",
        "                print(f\"   Avg CC: {avg_cc:.4f}\")\n",
        "                print(f\"   Time: {results['clustering']:.3f}s\")\n",
        "            except Exception as e:\n",
        "                print(f\"   Error: {e}\")\n",
        "                results['clustering'] = time.time() - start\n",
        "\n",
        "            # 7. Diameter approximation - fixed\n",
        "            print(\"7. Computing Diameter (approx)...\")\n",
        "            start = time.time()\n",
        "            try:\n",
        "                diameter_result = session.run(\"\"\"\n",
        "                    MATCH (start:User)\n",
        "                    WITH start LIMIT 10\n",
        "                    MATCH (end:User)\n",
        "                    WITH start, end LIMIT 50\n",
        "                    WHERE start <> end\n",
        "                    MATCH path = shortestPath((start)-[:VOTED_FOR*]-(end))\n",
        "                    WHERE path IS NOT NULL\n",
        "                    RETURN max(length(path)) AS max_diameter\n",
        "                \"\"\")\n",
        "                diameter = diameter_result.single()['max_diameter'] or 0\n",
        "                results['diameter'] = time.time() - start\n",
        "                print(f\"   Diameter: {diameter}\")\n",
        "                print(f\"   Time: {results['diameter']:.3f}s\")\n",
        "            except Exception as e:\n",
        "                print(f\"   Error: {e}\")\n",
        "                # Alternative diameter approach\n",
        "                try:\n",
        "                    diameter_result = session.run(\"\"\"\n",
        "                        MATCH (n:User)\n",
        "                        WITH n LIMIT 20\n",
        "                        MATCH (n)-[:VOTED_FOR*1..10]-(m:User)\n",
        "                        WHERE n <> m\n",
        "                        RETURN max(length(path)) AS max_diameter\n",
        "                    \"\"\")\n",
        "                    diameter = diameter_result.single()['max_diameter'] or 0\n",
        "                    results['diameter'] = time.time() - start\n",
        "                    print(f\"   Diameter (alt): {diameter}\")\n",
        "                    print(f\"   Time: {results['diameter']:.3f}s\")\n",
        "                except:\n",
        "                    results['diameter'] = time.time() - start\n",
        "\n",
        "        return results\n",
        "\n",
        "    except ServiceUnavailable as e:\n",
        "        print(f\"Service unavailable: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def test_conn(driver):\n",
        "    try:\n",
        "        with driver.session() as session:\n",
        "            result = session.run(\"RETURN 1 AS test\")\n",
        "            return result.single()['test'] == 1\n",
        "    except Exception as e:\n",
        "        print(f\"Connection failed: {e}\")\n",
        "        return False\n",
        "\n",
        "print(\"Testing connection...\")\n",
        "if test_conn(driver):\n",
        "    print(\"Connected! Running metrics...\")\n",
        "    results = run_metrics(driver)\n",
        "\n",
        "    if results:\n",
        "        print(\"=\" * 50)\n",
        "        print(\"RESULTS SUMMARY\")\n",
        "        print(\"=\" * 50)\n",
        "        for metric, exec_time in results.items():\n",
        "            print(f\"{metric:20s}: {exec_time:.3f}s\")\n",
        "    else:\n",
        "        print(\"Failed to compute metrics\")\n",
        "else:\n",
        "    print(\"Cannot connect to Neo4j\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXho0jz0prps",
        "outputId": "45320db7-aed7-4425-d4f6-a5f9a5960bf8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing connection...\n",
            "Connected! Running metrics...\n",
            "1. Counting nodes and edges...\n",
            "   Nodes: 7115, Edges: 103689\n",
            "   Time: 0.584s\n",
            "2. Sampling 500 nodes...\n",
            "   Sampled 500 nodes\n",
            "3. Computing WCC (approx)...\n",
            "   Largest WCC: 7066 nodes\n",
            "   Time: 17.542s\n",
            "4. Computing SCC (approx)...\n",
            "   Largest SCC: 7066 nodes\n",
            "   Time: 7.249s\n",
            "5. Computing triangle counts...\n",
            "   Triangles: 131925\n",
            "   Time: 1.444s\n",
            "6. Computing Clustering Coefficient...\n",
            "   Avg CC: 0.1611\n",
            "   Time: 2.465s\n",
            "7. Computing Diameter (approx)...\n",
            "   Diameter: 2\n",
            "   Time: 0.450s\n",
            "==================================================\n",
            "RESULTS SUMMARY\n",
            "==================================================\n",
            "basic_count         : 0.584s\n",
            "wcc                 : 17.542s\n",
            "scc                 : 7.249s\n",
            "triangles           : 1.444s\n",
            "clustering          : 2.465s\n",
            "diameter            : 0.450s\n"
          ]
        }
      ]
    }
  ]
}